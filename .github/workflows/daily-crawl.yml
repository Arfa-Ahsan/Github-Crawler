name: Daily GitHub Crawler

# Run every day at 2:00 AM UTC
# You can also trigger manually from the Actions tab
on:
  schedule:
    - cron: "0 3 * * *" # Daily at 2 AM UTC
  workflow_dispatch: # Allows manual trigger
  push:
    branches: [main] # Also run on push to test

jobs:
  crawl:
    runs-on: ubuntu-latest

    # PostgreSQL service container
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: github_crawler
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Setup PostgreSQL - Create tables and schemas
        env:
          PGHOST: localhost
          PGPORT: 5432
          PGDATABASE: github_crawler
          PGUSER: postgres
          PGPASSWORD: postgres
        run: |
          # Wait for PostgreSQL to be ready
          until pg_isready -h localhost -p 5432 -U postgres; do
            echo "Waiting for PostgreSQL to be ready..."
            sleep 2
          done

          echo "Creating database schema..."
          psql -h localhost -U postgres -d github_crawler -f database/schema.sql

          echo "Verifying tables created..."
          psql -h localhost -U postgres -d github_crawler -c "\dt"

      - name: Crawl Stars - Fetch 100,000 GitHub repositories
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DB_HOST: localhost
          DB_PORT: 5432
          DB_NAME: github_crawler
          DB_USER: postgres
          DB_PASSWORD: postgres
        run: |
          echo "Starting crawler to fetch 100,000 repositories..."
          python main.py

          echo "Crawler completed. Checking database..."
          psql -h localhost -U postgres -d github_crawler -c "SELECT COUNT(*) as total_repos FROM repositories;"

      - name: Export database to CSV
        env:
          PGHOST: localhost
          PGPORT: 5432
          PGDATABASE: github_crawler
          PGUSER: postgres
          PGPASSWORD: postgres
        run: |
          echo "Exporting repositories to CSV..."
          psql -h localhost -U postgres -d github_crawler -c "\COPY (SELECT * FROM repositories ORDER BY stars DESC) TO 'repositories.csv' WITH CSV HEADER;"

          echo "Exporting star history to CSV..."
          psql -h localhost -U postgres -d github_crawler -c "\COPY (SELECT * FROM repository_star_history ORDER BY recorded_at DESC) TO 'star_history.csv' WITH CSV HEADER;"

          echo "Creating summary statistics..."
          psql -h localhost -U postgres -d github_crawler -c "\COPY (
            SELECT 
              COUNT(*) as total_repositories,
              SUM(stars) as total_stars,
              AVG(stars) as avg_stars,
              MAX(stars) as max_stars,
              MIN(stars) as min_stars
            FROM repositories
          ) TO 'summary_stats.csv' WITH CSV HEADER;"

          echo "Files created:"
          ls -lh *.csv

      - name: Upload database dump as artifact
        uses: actions/upload-artifact@v4
        with:
          name: github-crawler-data-${{ github.run_number }}
          path: |
            repositories.csv
            star_history.csv
            summary_stats.csv
          retention-days: 30

      - name: Display summary
        run: |
          echo "=== Crawl Summary ==="
          cat summary_stats.csv

          echo ""
          echo "=== Top 10 Most Starred Repositories ==="
          head -n 11 repositories.csv | column -t -s,
